{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of the 2D Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The object of this notebook is to extract for each chanel RGB the mean and std to normalize our data during the training. To do that we will used the same architecture of our DataLoader <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Librairies #######\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from Loader_2D import CustomImageDataset\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########## Path ##########\n",
    "dataset_2D = './Database_2D/dataset_train'\n",
    "dataset_test_2D = './Database_2D/dataset_test'\n",
    "annotation_test = dataset_test_2D + '/annotation_test.txt'\n",
    "annotation = dataset_2D + '/annotation.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Image preprocessing #####\n",
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(576),  # image batch, resize smaller edge to 576\n",
    "        transforms.CenterCrop(576),  # image batch, center crop to square 576x576\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) what we want    \n",
    "        transforms.ToTensor()   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "############## Param√®tre ################\n",
    "\n",
    "\n",
    "############## Train Part ###############\n",
    "train_set = CustomImageDataset(\n",
    "    annotations_file = annotation,\n",
    "    img_dir = dataset_2D,\n",
    "    transform=preprocess\n",
    ")\n",
    "\n",
    "batch_size = len(train_set)\n",
    "print(batch_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zough/Documents/VAP/PFE/AI-for-coding-green-videos/IA/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/zough/Documents/VAP/PFE/AI-for-coding-green-videos/IA/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4098, 0.3934, 0.3934])\n",
      "std: tensor([0.3189, 0.3121, 0.3026])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean = 0.\n",
    "meansq = 0.\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        mean = inputs.mean(dim=(0, 2, 3))\n",
    "        meansq = (inputs**2).mean(dim=(0, 2, 3))\n",
    "\n",
    "\n",
    "std = torch.sqrt(meansq - mean**2)\n",
    "print(\"mean: \" + str(mean))\n",
    "print(\"std: \" + str(std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
